{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS4CbKOgccgV"
      },
      "outputs": [],
      "source": [
        "import struct\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def load_mnist_images(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        magic, num_images, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
        "        # we unpack the first 16 bytes so 4 * 32 Bits, each 32 bits signigies one of the four elements in lhs\n",
        "        # > signifies big endian ordering. I means unsigned 32 bit integers\n",
        "\n",
        "        assert magic == 2051, \"Invalid magic number for image file!\"\n",
        "        # Magic numbers exist to validate binary file types.\n",
        "        # All files of type idx3-ubyte (3-dimensional unsigned byte arrays) use the magic number 2051.\n",
        "\n",
        "        # Read raw bytes → convert to uint8 → reshape\n",
        "        \n",
        "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "        # np.frombuffer interprets the raw bytes directly as an array without copying — extremely fast.\n",
        "        # dtype=np.uint8 because MNIST pixels are 0–255.\n",
        "\n",
        "        data = data.reshape(num_images, rows, cols)\n",
        "        # Converts the flat stream of bytes into shape:\n",
        "        # (number_of_images, 28, 28)\n",
        "        # doesn't change the data per say but changes how you view it\n",
        "\n",
        "        # Normalize to [0,1] and add channel dimension\n",
        "        data = data.astype(np.float32) / 255.0\n",
        "        data = np.expand_dims(data, axis=1)  # shape: (N,1,28,28)\n",
        "\n",
        "        return torch.tensor(data)\n",
        "\n",
        "\n",
        "def load_mnist_labels(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        magic, num_labels = struct.unpack(\">II\", f.read(8))\n",
        "        assert magic == 2049, \"Invalid magic number for label file!\"\n",
        "\n",
        "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "\n",
        "        return torch.tensor(data, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acKpMEiDeSTc",
        "outputId": "461ad6a8-ed4d-415d-adc9-79ef3e65eade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 1, 28, 28]) torch.Size([60000])\n"
          ]
        }
      ],
      "source": [
        "# train_images_path = \"/content/drive/MyDrive/DCP/MNIST_Dataset/train-images-idx3-ubyte/train-images-idx3-ubyte\"\n",
        "# train_labels_path = \"/content/drive/MyDrive/DCP/MNIST_Dataset/train-labels-idx1-ubyte/train-labels-idx1-ubyte\"\n",
        "train_images_path = \"MNIST_Dataset/train-images-idx3-ubyte\"\n",
        "train_labels_path = \"MNIST_Dataset/train-labels-idx1-ubyte\"\n",
        "\n",
        "train_images = load_mnist_images(train_images_path)\n",
        "train_labels = load_mnist_labels(train_labels_path)\n",
        "\n",
        "print(train_images.shape, train_labels.shape)\n",
        "# for an individual shape the shape is 1,28,28 because its grayscale, if it was rgb then it would be 3,28,28, the first dimension is called channel\n",
        "# You need 4 dimensions because PyTorch CNNs expect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKXU05JpjJvF"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "#Dataset is an abstract base class provided by PyTorch.\n",
        "#It defines the interface your dataset must provide to work with PyTorch tools like DataLoader.\n",
        "\n",
        "class MNISTCustomDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    # as a child of dataset class\n",
        "    # pytorch expects you to implement __len__(self) and __getitem__(self, idx) \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]\n",
        "\n",
        "train_dataset = MNISTCustomDataset(train_images, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32FwvCeYfp2b"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MNIST_CNN(nn.Module):\n",
        "    # in the big picture transforms this (batch, 1, 28, 28) to this (batch, 10)\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Feature extractor\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Classifier\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input: (batch, 1, 28, 28)\n",
        "        x = self.pool(F.relu(self.conv1(x)))   # (batch, 32, 14, 14)\n",
        "        x = self.pool(F.relu(self.conv2(x)))   # (batch, 64, 7, 7)\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten: (batch, 64*7*7)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x  # raw logits (no softmax needed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlEmAqrNgJKY",
        "outputId": "90930af4-6d19-4c6f-9b18-3485c2ebf035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST_CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MNIST_CNN().to(device)\n",
        "# .to(device) moves all model parameters and buffers to the specified device.\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdi7YHYngabp"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# DataLoader takes a Dataset and turns it into batches\n",
        "# Batches are pulled lazily during training\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# meaning we'll use crossentropy loss as the metric to judge how off or on point the predictions are\n",
        "# this is the standard metric used in classification\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# we train all optimizable parameters and update them using adam optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTG9BJbzlBoX"
      },
      "outputs": [],
      "source": [
        "# best_model_path=\"/content/drive/MyDrive/DCP/best_model.pth\"\n",
        "best_model_path=\"best_model.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZAyisVXjTm2"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, loader, optimizer, criterion, device, epochs=5):\n",
        "    model.train()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        progress = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\")\n",
        "        # tqdm wraps loader to show batch progress, dynamic loss, accuracy etc\n",
        "        for images, labels in progress:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            # images and labels must be loaded to the same device, gpu memory or cpu ram\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images) # output shape is (batchsize,10)\n",
        "            loss = criterion(outputs, labels) # output shape is (batchsize,)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            # reset gradients each batch\n",
        "            loss.backward()\n",
        "            # Autograd computes ∂Loss/∂Weights for every parameter.\n",
        "            optimizer.step()\n",
        "            # Adam updates parameters using gradients.\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Accuracy calculation\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            acc = 100 * correct / total\n",
        "            # update progress bar\n",
        "            progress.set_postfix(loss=total_loss/total, accuracy=acc)\n",
        "\n",
        "        epoch_acc = 100 * correct / total\n",
        "        print(f\"\\nEpoch {epoch+1} completed | Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "        # Save best model\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"✔ Saved best model (Accuracy: {best_acc:.2f}%)\")\n",
        "\n",
        "    print(f\"\\nTraining finished. Best accuracy: {best_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq13lbXBjk6s",
        "outputId": "45b9604c-ed77-4b10-d134-3818ffa3a5ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5: 100%|██████████| 938/938 [00:05<00:00, 156.69batch/s, accuracy=94.5, loss=0.00281]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 completed | Accuracy: 94.53%\n",
            "✔ Saved best model (Accuracy: 94.53%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5: 100%|██████████| 938/938 [00:04<00:00, 227.16batch/s, accuracy=98.4, loss=0.000806]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 completed | Accuracy: 98.41%\n",
            "✔ Saved best model (Accuracy: 98.41%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/5: 100%|██████████| 938/938 [00:04<00:00, 224.28batch/s, accuracy=98.9, loss=0.000564]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 completed | Accuracy: 98.89%\n",
            "✔ Saved best model (Accuracy: 98.89%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/5: 100%|██████████| 938/938 [00:04<00:00, 204.38batch/s, accuracy=99.1, loss=0.00042]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 completed | Accuracy: 99.13%\n",
            "✔ Saved best model (Accuracy: 99.13%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/5: 100%|██████████| 938/938 [00:04<00:00, 223.06batch/s, accuracy=99.3, loss=0.000323]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 completed | Accuracy: 99.31%\n",
            "✔ Saved best model (Accuracy: 99.31%)\n",
            "\n",
            "Training finished. Best accuracy: 99.31%\n"
          ]
        }
      ],
      "source": [
        "train(model, train_loader, optimizer, criterion, device, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTfk-6Pfkx2V"
      },
      "source": [
        "The following cells will be for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mgb5105j4Lp"
      },
      "outputs": [],
      "source": [
        "# test_images_path = \"/content/drive/MyDrive/DCP/MNIST_Dataset/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte\"\n",
        "# test_labels_path = \"/content/drive/MyDrive/DCP/MNIST_Dataset/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte\"\n",
        "test_images_path = \"MNIST_Dataset/t10k-images-idx3-ubyte\"\n",
        "test_labels_path = \"MNIST_Dataset/t10k-labels-idx1-ubyte\"\n",
        "\n",
        "test_images = load_mnist_images(test_images_path)\n",
        "test_labels = load_mnist_labels(test_labels_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4yREx9EkNeZ"
      },
      "outputs": [],
      "source": [
        "test_dataset = MNISTCustomDataset(test_images, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6eoCb3nkPsk"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vReUQS3PkSwZ",
        "outputId": "3cf46132-59f6-46f0-8a1a-790f476b656a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 98.81\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = MNIST_CNN().to(device)\n",
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "\n",
        "test_acc = evaluate(model, test_loader, device)\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
